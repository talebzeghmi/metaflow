{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Competition | Titanic Machine Learning from Disaster\n",
    "\n",
    ">The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew.  This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    ">One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew.  Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    ">In this contest, we ask you to complete the analysis of what sorts of people were likely to survive.  In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    ">This Kaggle Getting Started Competition provides an ideal starting place for people who may not have a lot of experience in data science and machine learning.\"\n",
    "\n",
    "From the competition [homepage](http://www.kaggle.com/c/titanic-gettingStarted).\n",
    "\n",
    "\n",
    "### Goal for this Notebook:\n",
    "Show a simple example of an analysis of the Titanic disaster in Python using a full complement of PyData utilities. This is aimed for those looking to get into the field or those who are already in the field and looking to see an example of an analysis done with Python.\n",
    "\n",
    "#### This Notebook will show basic examples of: \n",
    "#### Data Handling\n",
    "*   Importing Data with Pandas\n",
    "*   Cleaning Data\n",
    "*   Exploring Data through Visualizations with Matplotlib\n",
    "\n",
    "#### Data Analysis\n",
    "*    Supervised Machine learning Techniques:\n",
    "    +   Logit Regression Model \n",
    "    +   Plotting results\n",
    "    +   Support Vector Machine (SVM) using 3 kernels\n",
    "    +   Basic Random Forest\n",
    "    +   Plotting results\n",
    "\n",
    "\n",
    "***To run this notebook interactively, get it from my Github [here](https://github.com/agconti/kaggle-titanic). The competition's website is located on [Kaggle.com](http://www.kaggle.com/c/titanic-gettingStarted).***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /srv/conda/envs/notebook/lib/python3.7/site-packages (3.3.4)\n",
      "Requirement already satisfied: statsmodels in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.12.2)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: pydot in /srv/conda/envs/notebook/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Requirement already satisfied: scikit-learn in /srv/conda/envs/notebook/lib/python3.7/site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: pandas>=0.21 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (1.2.4)\n",
      "Requirement already satisfied: scipy>=1.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (1.6.3)\n",
      "Requirement already satisfied: patsy>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from statsmodels) (0.5.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=6e4518acd40b6b75c4c60c722023077f159f6f74e30d5f06b0f98f6e1b5e9ac6\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn\n",
      "Successfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib statsmodels sklearn pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram') # to ensure we're able to view the diagrams in this Jupyter notebook environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Handling\n",
    "#### Let's read our data in using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show an overview of our data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look:\n",
    "\n",
    "Above is a summary of our data contained in a `Pandas` `DataFrame`. Think of a `DataFrame` as a Python's super charged version of the workflow in an Excel table. As you can see the summary holds quite a bit of information. First, it lets us know we have 891 observations, or passengers, to analyze here:\n",
    "    \n",
    "    Int64Index: 891 entries, 0 to 890\n",
    "\n",
    "Next it shows us all of the columns in `DataFrame`. Each column tells us something about each of our observations, like their `name`, `sex` or `age`. These colunms  are called a features of our dataset. You can think of the meaning of the words column and feature as interchangeable for this notebook. \n",
    "\n",
    "After each feature it lets us know how many values it contains. While most of our features have complete data on every observation, like the `survived` feature here: \n",
    "\n",
    "    survived    891  non-null values \n",
    "\n",
    "some are missing information, like the `age` feature: \n",
    "\n",
    "    age         714  non-null values \n",
    "\n",
    "These missing values are represented as `NaN`s.\n",
    "\n",
    "### Take care of missing values:\n",
    "The features `ticket` and `cabin` have many missing values and so can’t add much value to our analysis. To handle this we will drop them from the dataframe to preserve the integrity of our dataset.\n",
    "\n",
    "To do that we'll use this line of code to drop the features entirely:\n",
    "\n",
    "    df = df.drop(['ticket','cabin'], axis=1) \n",
    "\n",
    "\n",
    "While this line of code removes the `NaN` values from every remaining column / feature:\n",
    "   \n",
    "    df = df.dropna()\n",
    "     \n",
    "Now we have a clean and tidy dataset that is ready for analysis. Because `.dropna()` removes an observation from our data even if it only has 1 `NaN` in one of the features, it would have removed most of our dataset if we had not dropped the `ticket` and `cabin`  features first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Ticket','Cabin'], axis=1)\n",
    "# Remove NaN values\n",
    "df = df.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed look at how to use pandas for data analysis, the best resource is Wes Mckinney's [book](http://shop.oreilly.com/product/0636920023784.do). Additional interactive tutorials that cover all of the basics can be found [here](https://bitbucket.org/hrojas/learn-pandas) (they're free).  If you still need to be convinced about the power of pandas check out this wirlwhind [look](http://wesmckinney.com/blog/?p=647) at all that pandas can do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a Look at our data graphically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Passengers per boarding location')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifies the parameters of our graphs\n",
    "fig = plt.figure(figsize=(18,6), dpi=1600) \n",
    "alpha=alpha_scatterplot = 0.2 \n",
    "alpha_bar_chart = 0.55\n",
    "\n",
    "# lets us plot many diffrent shaped graphs together \n",
    "ax1 = plt.subplot2grid((2,3),(0,0))\n",
    "# plots a bar graph of those who surived vs those who did not.               \n",
    "df.Survived.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n",
    "# this nicely sets the margins in matplotlib to deal with a recent bug 1.3.1\n",
    "ax1.set_xlim(-1, 2)\n",
    "# puts a title on our graph\n",
    "plt.title(\"Distribution of Survival, (1 = Survived)\")    \n",
    "\n",
    "plt.subplot2grid((2,3),(0,1))\n",
    "plt.scatter(df.Survived, df.Age, alpha=alpha_scatterplot)\n",
    "# sets the y axis lable\n",
    "plt.ylabel(\"Age\")\n",
    "# formats the grid line style of our graphs                          \n",
    "plt.grid(b=True, which='major', axis='y')  \n",
    "plt.title(\"Survival by Age,  (1 = Survived)\")\n",
    "\n",
    "ax3 = plt.subplot2grid((2,3),(0,2))\n",
    "df.Pclass.value_counts().plot(kind=\"barh\", alpha=alpha_bar_chart)\n",
    "ax3.set_ylim(-1, len(df.Pclass.value_counts()))\n",
    "plt.title(\"Class Distribution\")\n",
    "\n",
    "plt.subplot2grid((2,3),(1,0), colspan=2)\n",
    "# plots a kernel density estimate of the subset of the 1st class passangers's age\n",
    "df.Age[df.Pclass == 1].plot(kind='kde')    \n",
    "df.Age[df.Pclass == 2].plot(kind='kde')\n",
    "df.Age[df.Pclass == 3].plot(kind='kde')\n",
    " # plots an axis lable\n",
    "plt.xlabel(\"Age\")    \n",
    "plt.title(\"Age Distribution within classes\")\n",
    "# sets our legend for our graph.\n",
    "plt.legend(('1st Class', '2nd Class','3rd Class'),loc='best') \n",
    "\n",
    "ax5 = plt.subplot2grid((2,3),(1,2))\n",
    "df.Embarked.value_counts().plot(kind='bar', alpha=alpha_bar_chart)\n",
    "ax5.set_xlim(-1, len(df.Embarked.value_counts()))\n",
    "# specifies the parameters of our graphs\n",
    "plt.title(\"Passengers per boarding location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Visualization:\n",
    "\n",
    "The point of this competition is to predict if an individual will survive based on the features in the data like:\n",
    " \n",
    " * Traveling Class (called pclass in the data)\n",
    " * Sex \n",
    " * Age\n",
    " * Fare Price\n",
    "\n",
    "Let’s see if we can gain a better understanding of who survived and died. \n",
    "\n",
    "\n",
    "First let’s plot a bar graph of those who Survived Vs. Those who did not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Survival Breakdown (1 = Survived, 0 = Died)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "fig, ax = plt.subplots()\n",
    "df.Survived.value_counts().plot(kind='barh', color=\"blue\", alpha=.65)\n",
    "ax.set_ylim(-1, len(df.Survived.value_counts())) \n",
    "plt.title(\"Survival Breakdown (1 = Survived, 0 = Died)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets use our model to predict the test set values and then save the results so they can be outputed to Kaggle\n",
    "### Read the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an acceptable formula for our machine learning algorithms\n",
    "formula_ml = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + Parch + C(Embarked) - 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "\"Well, What if this line / decision boundary thing doesn’t work at all.\"\n",
    "\n",
    "**Wikipedia, crystal clear as always:**\n",
    ">Random forests are an ensemble learning method for classification (and regression) that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes output by individual trees.\n",
    "\n",
    "**Once again, the skinny and why it matters to you:**\n",
    "\n",
    "There are always skeptics, and you just might be one about all the fancy lines we've created so far. Well for you, here’s another option; the Random Forest. This technique is a form of non-parametric modeling that does away with all those equations we created above, and uses raw computing power and a clever statistical observation to tease the structure out of the data. \n",
    "\n",
    "An anecdote to explain how this the forest works starts with the lowly gumball jar. We've all guess how many gumballs are in that jar at one time or another, and odds are not a single one of us guessed exactly right. Interestingly though, while each of our individual guesses for probably were wrong, the average of all of the guesses, if there were enough, usually comes out to be pretty close to the actual number of gumballs in the jar. Crazy, I know.  This idea is that clever statistical observation that lets random forests work.\n",
    "\n",
    "**How do they work?** A random forest algorithm randomly generates many extremely simple models to explain the variance observed in random subsections of our data.  These models are like our gumball guesses. They are all awful individually. Really awful. But once they are averaged, they can be powerful predictive tools. The averaging step is the secret sauce. While the vast majority of those models were extremely poor; they were all as bad as each other on average. So when their predictions are averaged together, the bad ones average their effect on our model out to zero. The thing that remains, *if anything*, is one or a handful of those models have stumbled upon the true structure of the data.\n",
    "The cell below shows the process of instantiating and fitting a random forest, generating predictions form the resulting model, and then scoring the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of Random Forest Predictions on the data was: 0.9452247191011236\n"
     ]
    }
   ],
   "source": [
    "# import the machine learning library that holds the randomforest\n",
    "import sklearn.ensemble as ske\n",
    "\n",
    "# Create the random forest model and fit the model to our training data\n",
    "y, x = dmatrices(formula_ml, data=df, return_type='dataframe')\n",
    "# RandomForestClassifier expects a 1 demensional NumPy array, so we convert\n",
    "y = np.asarray(y).ravel()\n",
    "#instantiate and fit our model\n",
    "results_rf = ske.RandomForestClassifier(n_estimators=100).fit(x, y)\n",
    "\n",
    "# Score the results\n",
    "score = results_rf.score(x, y)\n",
    "print(\"Mean accuracy of Random Forest Predictions on the data was: {0}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C(Pclass)[1]</th>\n",
       "      <th>C(Pclass)[2]</th>\n",
       "      <th>C(Pclass)[3]</th>\n",
       "      <th>C(Sex)[T.male]</th>\n",
       "      <th>C(Embarked)[T.Q]</th>\n",
       "      <th>C(Embarked)[T.S]</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C(Pclass)[1]  C(Pclass)[2]  C(Pclass)[3]  C(Sex)[T.male]  \\\n",
       "0             0.0           0.0           1.0             1.0   \n",
       "1             1.0           0.0           0.0             0.0   \n",
       "2             0.0           0.0           1.0             0.0   \n",
       "3             1.0           0.0           0.0             0.0   \n",
       "4             0.0           0.0           1.0             1.0   \n",
       "..            ...           ...           ...             ...   \n",
       "885           0.0           0.0           1.0             0.0   \n",
       "886           0.0           1.0           0.0             1.0   \n",
       "887           1.0           0.0           0.0             0.0   \n",
       "889           1.0           0.0           0.0             1.0   \n",
       "890           0.0           0.0           1.0             1.0   \n",
       "\n",
       "     C(Embarked)[T.Q]  C(Embarked)[T.S]   Age  SibSp  Parch  \n",
       "0                 0.0               1.0  22.0    1.0    0.0  \n",
       "1                 0.0               0.0  38.0    1.0    0.0  \n",
       "2                 0.0               1.0  26.0    0.0    0.0  \n",
       "3                 0.0               1.0  35.0    1.0    0.0  \n",
       "4                 0.0               1.0  35.0    0.0    0.0  \n",
       "..                ...               ...   ...    ...    ...  \n",
       "885               1.0               0.0  39.0    0.0    5.0  \n",
       "886               0.0               1.0  27.0    0.0    0.0  \n",
       "887               0.0               1.0  19.0    0.0    0.0  \n",
       "889               0.0               0.0  26.0    0.0    0.0  \n",
       "890               1.0               0.0  32.0    0.0    0.0  \n",
       "\n",
       "[712 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "# Pull out one tree from the forest\n",
    "tree = results_rf.estimators_[5]\n",
    "\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = x.columns, rounded = True, precision = 1)\n",
    "\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit depth of tree to 3 levels\n",
    "rf_small = ske.RandomForestClassifier(n_estimators=10, max_depth = 3).fit(x, y)\n",
    "\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = x.columns, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workshop\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](small_tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch     Fare Embarked  \n",
       "0        0   7.2500        S  \n",
       "1        0  71.2833        C  \n",
       "2        0   7.9250        S  \n",
       "3        0  53.1000        S  \n",
       "4        0   8.0500        S  \n",
       "..     ...      ...      ...  \n",
       "885      5  29.1250        Q  \n",
       "886      0  13.0000        S  \n",
       "887      0  30.0000        S  \n",
       "889      0  30.0000        C  \n",
       "890      0   7.7500        Q  \n",
       "\n",
       "[712 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting titanic_flow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile titanic_flow.py\n",
    "\n",
    "from metaflow import FlowSpec, step, Parameter\n",
    "from collections import defaultdict\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from statsmodels.nonparametric import smoothers_lowess\n",
    "from pandas import Series, DataFrame\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class TitanicFlow(FlowSpec):\n",
    "    max_depth = Parameter(\"max_depth\", default=10)\n",
    "    n_estimators=Parameter(\"n_estimators\", default=50)\n",
    "    parallelism = Parameter(\"parallelism\", default=2)\n",
    "    \n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        # Create an acceptable formula for our machine learning algorithms\n",
    "        self.formula_ml = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + Parch + C(Embarked) - 1'\n",
    "        self.next(self.feature_engineer)\n",
    "\n",
    "    @step\n",
    "    def feature_engineer(self):\n",
    "        df = pd.read_csv(\"data/train.csv\") \n",
    "        df = df.drop(['Ticket','Cabin'], axis=1)\n",
    "        # Remove NaN values\n",
    "        df = df.dropna() \n",
    "        \n",
    "        # Create the random forest model and fit the model to our training data\n",
    "        y, x = dmatrices(self.formula_ml, data=df, return_type='dataframe')\n",
    "        # RandomForestClassifier expects a 1 demensional NumPy array, so we convert\n",
    "        y = np.asarray(y).ravel()\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "        batch = self.n_estimators / self.parallelism\n",
    "        self.tree_batches = [int(batch) for x in range(int(self.n_estimators / batch))]\n",
    "        print(f\"self.tree_batches = {self.tree_batches}\")\n",
    "        self.next(self.model_train, foreach=\"tree_batches\")\n",
    "        \n",
    "    \n",
    "    @step\n",
    "    def model_train(self):\n",
    "        #instantiate and fit our model\n",
    "        self.random_forest = RandomForestClassifier(n_estimators=self.input, max_depth=self.max_depth).fit(self.x, self.y)\n",
    "        self.next(self.model_score)\n",
    "        \n",
    "    @step\n",
    "    def model_score(self):        \n",
    "        self.score = self.random_forest.score(self.x, self.y)\n",
    "        print(f\"Mean accuracy of Random Forest Predictions on the data was: {self.score}\")\n",
    "        self.next(self.combine_score)\n",
    "        \n",
    "    @step\n",
    "    def combine_score(self, inputs):        \n",
    "        # Score the results\n",
    "        def combine_rfs(input_a, input_b):\n",
    "            input_a.random_forest.estimators_ += input_b.random_forest.estimators_\n",
    "            input_a.random_forest.n_estimators = len(input_a.random_forest.estimators_)\n",
    "            return input_a.random_forest\n",
    "        print(\"----inputs\", list(inputs))\n",
    "        self.random_forest_combined = reduce(combine_rfs, inputs)\n",
    "        \n",
    "        self.merge_artifacts(inputs, include=['x', 'y'])\n",
    "        self.combined_score = self.random_forest_combined.score(self.x, self.y)\n",
    "        print(f\"Mean accuracy of Combined Random Forest Predictions on the data was: {self.combined_score}\")\n",
    "        self.next(self.end)       \n",
    "\n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    TitanicFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python titanic_flow.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Task, Step, Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step(f\"{Flow('TitanicFlow').latest_run.pathspec}/combine_score\").task.data.combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pathspec = Flow(\"TitanicFlow\").latest_run.pathspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Step(f\"{run_pathspec}/model_score\").task.data.random_forest.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Step(f\"{run_pathspec}/combine_score\").task.data.random_forest_combined.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
